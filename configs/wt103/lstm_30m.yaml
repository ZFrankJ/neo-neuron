model_name: lstm
dataset_name: wikitext
dataset_config: wikitext-103-raw-v1
train_split: train
val_split: validation
test_split: test

d_model: 512
d_embed: 512
n_layers: 2
dropout: 0.1
tie_embeddings: true
vocab_size: 50257

block_size: 256
batch_size: 16
epochs: 10
lr: 3e-4
weight_decay: 1e-2
grad_clip: 1.0

tbptt_len: 256
train_regime: random
stream_state: false

cosine: true
warmup_epochs: 2
min_lr: 3e-5

seed: 42
save_dir: checkpoints
run_tag: wt103_lstm_30m
save_each_epoch: true
resume_path: ""
restart_after_epoch: true
restart_done: false
